x
y
cbind(x,y,z)
rbind(x,y,z)
as.matrix(c(x,y,z))
(c(x,y,z)
c(x,y,z)
generate.data = function(alphax, betax, alphay, betay, eta, N) {
z = rnorm(N,0,1)
x = y = numeric(N)
## px is an N x length(alphax) matrix.
## Each row has the TRUE cummulative probabilities for each subject.
px = (1 + exp(- outer(alphax, betax*z, "+"))) ^ (-1)
aa = runif(N)
for(i in 1:N)
x[i] = sum(aa[i] > px[,i])
x = as.numeric(as.factor(x))
py = (1 + exp(- outer(alphay, betay*z+eta[x], "+"))) ^ (-1)
aa = runif(N)
for(i in 1:N)
y[i] = sum(aa[i] > py[,i])
y = as.numeric(as.factor(y))
## y = y+1 may have category gaps if there are small probability categories.
return(c(x,y,z))
}
data = generate.data(alphax, betax, alphay, betay, eta, N)
data[1:500]
z = data[-(1:(2*N))]
z
z = as.matrix(data[-(1:(2*N))])
nax = nx - 1
nay = ny - 1
nz = ncol(z)
N = length(y)
assign("EE", 0, pos=1)
suppressWarnings(tryCatch(assign("modxz", lrm(x ~ z, tol=1e-50, maxit=100)),
error = function(x) assign("EE", 1, pos=1)))
suppressWarnings(tryCatch(assign("modyz", lrm(y ~ z, tol=1e-50, maxit=100)),
error = function(x) assign("EE", 1, pos=1)))
if(EE == 1) return(list(stat=rep(NA,1), pred.probx=NULL, pred.proby=NULL))
px = (1 + exp(outer(modxz$coeff[1:nax],
as.vector(z%*%modxz$coeff[-(1:nax)]), "+"))) ^ (-1)
require(rms)  ## for the lrm() function
assign("EE", 0, pos=1)
suppressWarnings(tryCatch(assign("modxz", lrm(x ~ z, tol=1e-50, maxit=100)),
error = function(x) assign("EE", 1, pos=1)))
suppressWarnings(tryCatch(assign("modyz", lrm(y ~ z, tol=1e-50, maxit=100)),
error = function(x) assign("EE", 1, pos=1)))
if(EE == 1) return(list(stat=rep(NA,1), pred.probx=NULL, pred.proby=NULL))
px = (1 + exp(outer(modxz$coeff[1:nax],
as.vector(z%*%modxz$coeff[-(1:nax)]), "+"))) ^ (-1)
nx = length(table(x))
ny = length(table(y))
nax = nx - 1
nay = ny - 1
nz = ncol(z)
N = length(y)
assign("EE", 0, pos=1)
suppressWarnings(tryCatch(assign("modxz", lrm(x ~ z, tol=1e-50, maxit=100)),
error = function(x) assign("EE", 1, pos=1)))
suppressWarnings(tryCatch(assign("modyz", lrm(y ~ z, tol=1e-50, maxit=100)),
error = function(x) assign("EE", 1, pos=1)))
if(EE == 1) return(list(stat=rep(NA,1), pred.probx=NULL, pred.proby=NULL))
px = (1 + exp(outer(modxz$coeff[1:nax],
as.vector(z%*%modxz$coeff[-(1:nax)]), "+"))) ^ (-1)
py = (1 + exp(outer(modyz$coeff[1:nay],
as.vector(z%*%modyz$coeff[-(1:nay)]), "+"))) ^ (-1)
pred.probx = rbind(px,1) - rbind(0,px)
pred.proby = rbind(py,1) - rbind(0,py)
sum.matrix = tcrossprod(pred.proby, pred.probx)
T1 = tau(table(y,x))$tau - tau(sum.matrix)$tau
if(nx0 > nx) {
px.fill = matrix(0, nx0-1, N)
catx = as.numeric(names(table(x)))
kk = 0
for(i in 1:(nx0-1)) {
if(i %in% catx) kk = kk + 1
if(kk == 0) {
px.fill[i,] = 0
} else if(kk == nx) {
px.fill[i,] = 1
} else px.fill[i,] = px[kk,]
}
px = px.fill
}
if(ny0 > ny) {
py.fill = matrix(0, ny0-1, N)
caty = as.numeric(names(table(y)))
kk = 0
for(i in 1:(ny0-1)) {
if(i %in% caty) kk = kk + 1
if(kk == 0) {
py.fill[i,] = 0
} else if(kk == ny) {
py.fill[i,] = 1
} else py.fill[i,] = py[kk,]
}
py = py.fill
}
low.x = rbind(0,px)[cbind(x,1:N)]
hi.x = 1 - rbind(px,1)[cbind(x,1:N)]
low.y = rbind(0,py)[cbind(y,1:N)]
hi.y = 1 - rbind(py,1)[cbind(y,1:N)]
T2 = cor(hi.x - low.x, hi.y - low.y)
Cprob = low.x*low.y + hi.x*hi.y
Dprob = low.x*hi.y + hi.x*low.y
Cmean = mean(Cprob)
Dmean = mean(Dprob)
T3 = Cmean - Dmean
modyzx.con = lrm(y ~ z + x, data=data)
modyzx.con = lrm(y ~ z + x)
modyzx.dis = lrm(y ~ z + x,data=list(y=y,z=z,x=as.factor(x)))
pval.conyx = anova(modyzx.con)[2,3]
pval.disyx = anova(modyzx.dis)[2,3]
T4=-2*log(pval.conyx)-2*log(pval.disyx)
T6=min(pval.disyx,pval.conyx)
modxzy.con = lrm(x ~ z + y, data=data)
modxzy.con = lrm(x ~ z + y)
modxzy.dis = lrm(x ~ z + y,data=list(x=x,z=z,y=as.factor(y)))
pval.conxy = anova(modxzy.con)[2,3]
pval.disxy = anova(modxzy.dis)[2,3]
T5=T4-2*log(pval.conxy)-2*log(pval.disxy)
T7=min(T6,pval.disxy,pval.conxy)
list(stat=c(T1,T2,T3,T4,T5,T6,T7),pval=c(pval.conyx,pval.disyx,pval.conxy,pval.disxy),
pred.probx=pred.probx,
pred.proby=pred.proby)
COBOT.stat = function(data, nx0, ny0) {
require(rms)  ## for the lrm() function
N=length(data)/3
x = data[1:N]
y = data[(N+1):(2*N)]
z = as.matrix(data[-(1:(2*N))])
nx = length(table(x))
ny = length(table(y))
nax = nx - 1
nay = ny - 1
nz = ncol(z)
N = length(y)
## Fit separate proportional odds models under the null
## lrm() may fail if the slope is very close to zero.  This is rare but
## needs to be taken care of.  NAs are returned when this happens.
## polr() in MASS library seems to have problems too.
##  modxz = lrm(x ~ z)
##  modyz = lrm(y ~ z)
assign("EE", 0, pos=1)
suppressWarnings(tryCatch(assign("modxz", lrm(x ~ z, tol=1e-50, maxit=100)),
error = function(x) assign("EE", 1, pos=1)))
suppressWarnings(tryCatch(assign("modyz", lrm(y ~ z, tol=1e-50, maxit=100)),
error = function(x) assign("EE", 1, pos=1)))
if(EE == 1) return(list(stat=rep(NA,1), pred.probx=NULL, pred.proby=NULL))
## Obtain predicted cummulative probabilities.
## Each column is for a subject
px = (1 + exp(outer(modxz$coeff[1:nax],
as.vector(z%*%modxz$coeff[-(1:nax)]), "+"))) ^ (-1)
py = (1 + exp(outer(modyz$coeff[1:nay],
as.vector(z%*%modyz$coeff[-(1:nay)]), "+"))) ^ (-1)
## sum of predicted probability matrix
pred.probx = rbind(px,1) - rbind(0,px)
pred.proby = rbind(py,1) - rbind(0,py)
sum.matrix = tcrossprod(pred.proby, pred.probx)
## T1 is to contrast tau of observed and expected frequencies.
T1 = tau(table(y,x))$tau - tau(sum.matrix)$tau
# ## Fill in the categories that are missed in the empirical data set
if(nx0 > nx) {
px.fill = matrix(0, nx0-1, N)
catx = as.numeric(names(table(x)))
kk = 0
for(i in 1:(nx0-1)) {
if(i %in% catx) kk = kk + 1
if(kk == 0) {
px.fill[i,] = 0
} else if(kk == nx) {
px.fill[i,] = 1
} else px.fill[i,] = px[kk,]
}
px = px.fill
}
if(ny0 > ny) {
py.fill = matrix(0, ny0-1, N)
caty = as.numeric(names(table(y)))
kk = 0
for(i in 1:(ny0-1)) {
if(i %in% caty) kk = kk + 1
if(kk == 0) {
py.fill[i,] = 0
} else if(kk == ny) {
py.fill[i,] = 1
} else py.fill[i,] = py[kk,]
}
py = py.fill
}
## components of residuals
low.x = rbind(0,px)[cbind(x,1:N)]
hi.x = 1 - rbind(px,1)[cbind(x,1:N)]
low.y = rbind(0,py)[cbind(y,1:N)]
hi.y = 1 - rbind(py,1)[cbind(y,1:N)]
## T2 is correlation of residuals
T2 = cor(hi.x - low.x, hi.y - low.y)
Cprob = low.x*low.y + hi.x*hi.y
Dprob = low.x*hi.y + hi.x*low.y
Cmean = mean(Cprob)
Dmean = mean(Dprob)
## T3 is Cmean-Dmean
T3 = Cmean - Dmean
modyzx.con = lrm(y ~ z + x)
modyzx.dis = lrm(y ~ z + x,data=list(y=y,z=z,x=as.factor(x)))
pval.conyx = anova(modyzx.con)[2,3]
pval.disyx = anova(modyzx.dis)[2,3]
## conbime
T4=-2*log(pval.conyx)-2*log(pval.disyx)
T6=min(pval.disyx,pval.conyx)
##
modxzy.con = lrm(x ~ z + y)
modxzy.dis = lrm(x ~ z + y,data=list(x=x,z=z,y=as.factor(y)))
pval.conxy = anova(modxzy.con)[2,3]
pval.disxy = anova(modxzy.dis)[2,3]
T5=T4-2*log(pval.conxy)-2*log(pval.disxy)
T7=min(T6,pval.disxy,pval.conxy)
##
list(stat=c(T1,T2,T3,T4,T5,T6,T7),pval=c(pval.conyx,pval.disyx,pval.conxy,pval.disxy),
pred.probx=pred.probx,
pred.proby=pred.proby)
}
N=length(data)/3
x = data[1:N]
y = data[(N+1):(2*N)]
z = as.matrix(data[-(1:(2*N))])
nx = length(table(x))
ny = length(table(y))
nxny = nx*ny
nxnym1 = nxny - 1
N = length(data$y)
test.stat =COBOT.stat(data, nx, ny)
nxnym1 = nxny - 1
test.stat =COBOT.stat(data, nx, ny)
cum.mult.prob = matrix(, nxnym1, N)
for(i in 1:N)
cum.mult.prob[,i] = cumsum(outer(test.stat$pred.proby[,i], test.stat$pred.probx[,i]))[-nxny]
xyemp = matrix(,N,Nemp)
aa = matrix(runif(N*Nemp), N)
for(k in 1:N)
xyemp[k,] = outer(aa[k,], cum.mult.prob[,k], ">") %*% rep(1,nxnym1)
xemp = xyemp %/% ny + 1
yemp = xyemp %% ny + 1
test.stat.emp = matrix(,7,Nemp)
for(j in 1:Nemp) {
test.stat.emp[,j] = COBOT.stat(list(x=xemp[,j], y=yemp[,j], z=data$z),
nx, ny)$stat
}
for(j in 1:Nemp) {
test.stat.emp[,j] = COBOT.stat(list(x=xemp[,j], y=yemp[,j], z=z),
nx, ny)$stat
}
pvala = apply(abs(test.stat$stat[1:5]) <= abs(test.stat.emp[1:5,]), 1, mean, na.rm=T)
pvalb =apply(abs(test.stat$stat[6:7]) >= abs(test.stat.emp[6:7,]), 1, mean, na.rm=T)
c(pvala,pvalb,test.stat$pval)
test.stat
test.stat$stat
pvala = apply(abs(test.stat$stat[1:5]) <= abs(test.stat.emp[1:5,]), 1, mean, na.rm=T)
test.stat.emp
test.stat.emp = matrix(,7,Nemp)
for(j in 1:Nemp) {
test.stat.emp[,j] = COBOT.stat(list(x=xemp[,j], y=yemp[,j], z=z),
nx, ny)$stat
}
test.stat.emp
cum.mult.prob = matrix(, nxnym1, N)
for(i in 1:N)
cum.mult.prob[,i] = cumsum(outer(test.stat$pred.proby[,i], test.stat$pred.probx[,i]))[-nxny]
cum.mult.prob
nxny = nx*ny
nxnym1 = nxny - 1
cum.mult.prob = matrix(, nxnym1, N)
for(i in 1:N)
cum.mult.prob[,i] = cumsum(outer(test.stat$pred.proby[,i], test.stat$pred.probx[,i]))[-nxny]
View(cum.mult.prob)
xyemp = matrix(,N,Nemp)
aa = matrix(runif(N*Nemp), N)
for(k in 1:N)
xyemp[k,] = outer(aa[k,], cum.mult.prob[,k], ">") %*% rep(1,nxnym1)
xemp = xyemp %/% ny + 1
yemp = xyemp %% ny + 1
test.stat.emp = matrix(,7,Nemp)
for(j in 1:Nemp) {
test.stat.emp[,j] = COBOT.stat(list(x=xemp[,j], y=yemp[,j], z=z),
nx, ny)$stat
}
pvala = apply(abs(test.stat$stat[1:5]) <= abs(test.stat.emp[1:5,]), 1, mean, na.rm=T)
xemp
yemp
for(j in 1:Nemp) {
test.stat.emp[,j] = COBOT.stat(c(xemp[,j], yemp[,j], z=z),
nx, ny)$stat
}
pvala = apply(abs(test.stat$stat[1:5]) <= abs(test.stat.emp[1:5,]), 1, mean, na.rm=T)
pvalb =apply(abs(test.stat$stat[6:7]) >= abs(test.stat.emp[6:7,]), 1, mean, na.rm=T)
c(pvala,pvalb,test.stat$pval)
data=sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N)
eta
generate.data = function(k,alphax, betax, alphay, betay, eta, N) {
z = rnorm(N,0,1)
x = y = numeric(N)
## px is an N x length(alphax) matrix.
## Each row has the TRUE cummulative probabilities for each subject.
px = (1 + exp(- outer(alphax, betax*z, "+"))) ^ (-1)
aa = runif(N)
for(i in 1:N)
x[i] = sum(aa[i] > px[,i])
x = as.numeric(as.factor(x))
py = (1 + exp(- outer(alphay, betay*z+eta[x], "+"))) ^ (-1)
aa = runif(N)
for(i in 1:N)
y[i] = sum(aa[i] > py[,i])
y = as.numeric(as.factor(y))
## y = y+1 may have category gaps if there are small probability categories.
return(c(x,y,z))
}
data=sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N)
class(data)
pval=sapply(data,COBOT.emp,Nemp)
COBOT.emp(data, Nemp)
source("ca.r")
COBOT.emp(data, Nemp)
data = generate.data(1,alphax, betax, alphay, betay, eta, N)
COBOT.emp(data, Nemp)
Nemp = 10
COBOT.emp(data, Nemp)
data=sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N)
system.time( for (ii in 1:NREPL) {
data = generate.data(1,alphax, betax, alphay, betay, eta, N)
pval.emp[ii,] = COBOT.emp(data, Nemp)
})
pval.emp = matrix(,NREPL,11)
system.time( for (ii in 1:NREPL) {
data = generate.data(1,alphax, betax, alphay, betay, eta, N)
pval.emp[ii,] = COBOT.emp(data, Nemp)
})
system.time( for (ii in 1:NREPL) {
data = generate.data(1,alphax, betax, alphay, betay, eta, N)
pval.emp[ii,] = COBOT.emp(data, Nemp)
})
Nemp = 10
NREPL = 100
system.time( for (ii in 1:NREPL) {
data = generate.data(1,alphax, betax, alphay, betay, eta, N)
pval.emp[ii,] = COBOT.emp(data, Nemp)
})
system.time({
data=sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N)
pval=sapply(data,COBOT.emp,Nemp)
})
system.time({
data=as.data.frame(sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N))
pval=sapply(data,COBOT.emp,Nemp)
})
alpha<-apply(pval<p,2,mean,rm.na=T)
p=0.05
alpha<-apply(pval<p,2,mean,rm.na=T)
alpha
pval
data
pval
data[1,]
data[,1]
?sapply
data=as.data.frame(sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N))
pval=lapply(data,COBOT.emp,Nemp)
NREPL = 10
data=as.data.frame(sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N))
pval=lapply(data,COBOT.emp,Nemp)
pval
data=as.data.frame(sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N))
pval=lapply(data,COBOT.emp,Nemp)
pval
NREPL = 50
data=as.data.frame(sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N))
pval=lapply(data,COBOT.emp,Nemp)
pval
alpha<-lapply(pval<p,mean,rm.na=T)
p=0.05
alpha<-sapply(pval<p,mean,rm.na=T)
pval[3]
pval<-as.matrix(pval)
pval
pval=lapply(data,COBOT.emp,Nemp)
pvalm<-as.matrix(pval)
pvalm
pval
unlist(pval)
pval=sapply(data,COBOT.emp,Nemp)
pval
alpha<-apply(pval<p,1,mean,rm.na=T)
alpha
pval=lapply(data,COBOT.emp,Nemp)
unlist(pval)[1:11]
pval$V1
pvalm<-matrix(unlist(pval),nrow = NREPL)
pvalm[1,]
pvalm<-matrix(unlist(pval),nrow = NREPL,byrow = T)
pvalm[1,]
alpha<-apply(pval<p,2,mean,rm.na=T)
alpha<-apply(pvalm<p,2,mean,rm.na=T)
alpha
system.time({
data=as.data.frame(sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N))
pval=lapply(data,COBOT.emp,Nemp)
})
system.time( for (ii in 1:NREPL) {
data = generate.data(1,alphax, betax, alphay, betay, eta, N)
pval[ii,] = COBOT.emp(data, Nemp)
})
pval = matrix(,NREPL,11)
system.time( for (ii in 1:NREPL) {
data = generate.data(1,alphax, betax, alphay, betay, eta, N)
pval[ii,] = COBOT.emp(data, Nemp)
})
setwd("C:/Users/o0/Desktop/ordinal data/simulation/Combi_ordinal/testspeed")
#### Need all functions defined in COBOT-analysis.r
source("ca.r")
#### Function for simulating data
generate.data = function(k,alphax, betax, alphay, betay, eta, N) {
z = rnorm(N,0,1)
x = y = numeric(N)
## px is an N x length(alphax) matrix.
## Each row has the TRUE cummulative probabilities for each subject.
px = (1 + exp(- outer(alphax, betax*z, "+"))) ^ (-1)
aa = runif(N)
for(i in 1:N)
x[i] = sum(aa[i] > px[,i])
x = as.numeric(as.factor(x))
py = (1 + exp(- outer(alphay, betay*z+eta[x], "+"))) ^ (-1)
aa = runif(N)
for(i in 1:N)
y[i] = sum(aa[i] > py[,i])
y = as.numeric(as.factor(y))
## y = y+1 may have category gaps if there are small probability categories.
return(c(x,y,z))
}
#### Start simulations
ptm=proc.time()
N = 500
Nemp = 1000
NREPL = 1000
# 1. X_5. Y_4
alphay = c(-1, 0, 1)
betay = -0.5
alphax = c(-1, 0, 1, 2)
betax = 1
eta0 = rep(0,5)
eta1 =c(-0.3,-0.15,0,0.15,0.3)
eta2= c(-0.21,-0.18,0.10,0.22,0.24)
eta3 = c(-0.35,0.4,0.2,0,-0.15)
# #null distribution
data=as.data.frame(sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta, N))
pval=lapply(data,COBOT.emp,Nemp)
proc.time()-ptm
##Computer Type I error and power
library(xlsx)
p=0.05
pvalm<-matrix(unlist(pval),nrow = NREPL,byrow = T)
alpha<-apply(pvalm<p,2,mean,rm.na=T)
# setwd("J:/Onedirve/OneDrive/Documents/result/cob2/X_5_Y_4")
# write.xlsx(x = alpha, file = "result_alpha.xlsx",
#            sheetName = "result", row.names =F,col.names = F)
setwd("C:/Users/o0/Desktop/ordinal data/simulation/Combi_ordinal/testspeed")
#### Need all functions defined in COBOT-analysis.r
source("ca.r")
#### Function for simulating data
generate.data = function(k,alphax, betax, alphay, betay, eta, N) {
z = rnorm(N,0,1)
x = y = numeric(N)
## px is an N x length(alphax) matrix.
## Each row has the TRUE cummulative probabilities for each subject.
px = (1 + exp(- outer(alphax, betax*z, "+"))) ^ (-1)
aa = runif(N)
for(i in 1:N)
x[i] = sum(aa[i] > px[,i])
x = as.numeric(as.factor(x))
py = (1 + exp(- outer(alphay, betay*z+eta[x], "+"))) ^ (-1)
aa = runif(N)
for(i in 1:N)
y[i] = sum(aa[i] > py[,i])
y = as.numeric(as.factor(y))
## y = y+1 may have category gaps if there are small probability categories.
return(c(x,y,z))
}
#### Start simulations
ptm=proc.time()
N = 500
Nemp = 1000
NREPL = 1000
# 1. X_5. Y_4
alphay = c(-1, 0, 1)
betay = -0.5
alphax = c(-1, 0, 1, 2)
betax = 1
eta0 = rep(0,5)
eta1 =c(-0.3,-0.15,0,0.15,0.3)
eta2= c(-0.21,-0.18,0.10,0.22,0.24)
eta3 = c(-0.35,0.4,0.2,0,-0.15)
# #null distribution
data=as.data.frame(sapply(1:NREPL,generate.data,alphax, betax, alphay, betay, eta0, N))
pval=lapply(data,COBOT.emp,Nemp)
proc.time()-ptm
##Computer Type I error and power
library(xlsx)
p=0.05
pvalm<-matrix(unlist(pval),nrow = NREPL,byrow = T)
alpha<-apply(pvalm<p,2,mean,rm.na=T)
# setwd("J:/Onedirve/OneDrive/Documents/result/cob2/X_5_Y_4")
# write.xlsx(x = alpha, file = "result_alpha.xlsx",
#            sheetName = "result", row.names =F,col.names = F)
